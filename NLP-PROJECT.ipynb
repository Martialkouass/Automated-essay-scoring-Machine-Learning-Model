{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"#\"><img src = \"https://3d-media.pro/images/Logo-DATA-For-Developpement.png\" width = 250, align = \"center\"></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\"> Project: Develop an end-to-end Machine Learning Pipeline </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center;\">Instructor: Assan Sanogo</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Project Overview:</h3>\n",
    "<p>This project is based on a dataset of 7000+ essays graded by English specialists. This data problem is close to a real-world situation as it requires to be cleaned, an EDA must be thoroughly done so that the team can engineer relevant features.</p>\n",
    "<p>This project is a NLP problem that will be the foundation of an English program used by the company Easy Sailing Language Training. Their ambition is to have a reliable tool to assess new students’ ability to write in English according to the IELTS grading system. In turn it would help prospective students in knowing how much time they need to invest to get to the next level.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Introduction: Business Problem](#introduction)\n",
    "* [Data](#data)\n",
    "    * [data processing](#dataprocessing)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis](#analysis)\n",
    "* [Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: Business Problem <a name=\"introduction\"></a>\n",
    "<p><strong>DETEMLP</strong> is a project that aims to develop an end-to-end pipeline to process essays and output a grade describing the level of English proficiency. This project is based on a dataset of 7000+ essays graded by English specialists. </p>\n",
    "<p>The goal is to <strong>create a reliable tool to assess new students’ ability to write in English according to the IELTS grading system</strong>. In this project, we’ll be using data processing, data cleaning, and NLP techniques, including the librairie Spacy. If during this trip we struggle with the dataset, we might reframe the problem as a classification problem.</p>\n",
    "<p>Let’s dive in</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data<a name=\"data\"></a>\n",
    "<p>\n",
    "Our data collection has been really simplify, here the list of our dataset : </p>\n",
    "<ul>\n",
    "<li>test_set.tsv</li>\n",
    "<li>training_set_rel3.tsv</li>\n",
    "<li>training_set_rel3.xls</li>\n",
    "<li>training_set_rel3.xlsx</li>\n",
    "<li>valid_sample_submission_1_column.csv</li>\n",
    "<li>valid_sample_submission_1_column_no_header.csv</li>\n",
    "<li>valid_sample_submission_2_column.csv</li>\n",
    "<li>valid_sample_submission_5_column.csv</li>\n",
    "<li>valid_set.tsv</li>\n",
    "<li>valid_set.xls</li>\n",
    "<li>valid_set.xlsx </li>\n",
    "</ul>\n",
    "\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Data processing<a name=\"dataprocessing\"></a></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('vader_lexicon')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# import librairies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams, pos_tag\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "import language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  \n",
       "0                  1788                   NaN  \n",
       "1                  1789                   NaN  \n",
       "2                  1790                   NaN  \n",
       "3                  1791                   NaN  \n",
       "4                  1792                   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look to valid set\n",
    "df_valid_set = pd.read_csv(\"valid_set.tsv\",sep=\"\\t\",encoding=\"latin1\")\n",
    "df_valid_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4218.000000</td>\n",
       "      <td>4218.000000</td>\n",
       "      <td>4218.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11282.446420</td>\n",
       "      <td>4.123518</td>\n",
       "      <td>13735.433618</td>\n",
       "      <td>7178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6173.633131</td>\n",
       "      <td>2.117188</td>\n",
       "      <td>6964.020021</td>\n",
       "      <td>346.698716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1788.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1788.000000</td>\n",
       "      <td>6579.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5243.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7508.500000</td>\n",
       "      <td>6878.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10995.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13995.500000</td>\n",
       "      <td>7178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16852.750000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>19852.750000</td>\n",
       "      <td>7477.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21938.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24938.000000</td>\n",
       "      <td>7777.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id    essay_set  domain1_predictionid  domain2_predictionid\n",
       "count   4218.000000  4218.000000           4218.000000            600.000000\n",
       "mean   11282.446420     4.123518          13735.433618           7178.000000\n",
       "std     6173.633131     2.117188           6964.020021            346.698716\n",
       "min     1788.000000     1.000000           1788.000000           6579.000000\n",
       "25%     5243.250000     2.000000           7508.500000           6878.500000\n",
       "50%    10995.500000     4.000000          13995.500000           7178.000000\n",
       "75%    16852.750000     6.000000          19852.750000           7477.500000\n",
       "max    21938.000000     8.000000          24938.000000           7777.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4218 entries, 0 to 4217\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   essay_id              4218 non-null   int64  \n",
      " 1   essay_set             4218 non-null   int64  \n",
      " 2   essay                 4218 non-null   object \n",
      " 3   domain1_predictionid  4218 non-null   int64  \n",
      " 4   domain2_predictionid  600 non-null    float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 164.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_valid_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay_weight</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_id  essay_id  essay_set  essay_weight  predicted_score\n",
       "0           1788      1788          1           1.0                7\n",
       "1           1789      1789          1           1.0                8\n",
       "2           1790      1790          1           1.0                9\n",
       "3           1791      1791          1           1.0                9\n",
       "4           1792      1792          1           1.0                9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid sample submission\n",
    "df_sample_submission = pd.read_csv(\"valid_sample_submission_5_column.csv\",encoding=\"latin1\")\n",
    "df_sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set\n",
    "df_training_set = pd.read_csv(\"training_set_rel3.tsv\",sep=\"\\t\",encoding=\"latin1\")\n",
    "df_training_set.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>723.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10295.395808</td>\n",
       "      <td>4.179485</td>\n",
       "      <td>4.127158</td>\n",
       "      <td>4.137408</td>\n",
       "      <td>37.828125</td>\n",
       "      <td>6.800247</td>\n",
       "      <td>3.333889</td>\n",
       "      <td>3.330556</td>\n",
       "      <td>3.333889</td>\n",
       "      <td>2.444154</td>\n",
       "      <td>...</td>\n",
       "      <td>2.635689</td>\n",
       "      <td>2.710297</td>\n",
       "      <td>3.777317</td>\n",
       "      <td>3.589212</td>\n",
       "      <td>3.945312</td>\n",
       "      <td>3.890625</td>\n",
       "      <td>4.078125</td>\n",
       "      <td>3.992188</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6309.074105</td>\n",
       "      <td>2.136913</td>\n",
       "      <td>4.212544</td>\n",
       "      <td>4.264330</td>\n",
       "      <td>5.240829</td>\n",
       "      <td>8.970705</td>\n",
       "      <td>0.729103</td>\n",
       "      <td>0.726807</td>\n",
       "      <td>0.729103</td>\n",
       "      <td>1.211730</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142566</td>\n",
       "      <td>1.045795</td>\n",
       "      <td>0.689401</td>\n",
       "      <td>0.693256</td>\n",
       "      <td>0.643668</td>\n",
       "      <td>0.630390</td>\n",
       "      <td>0.622535</td>\n",
       "      <td>0.509687</td>\n",
       "      <td>0.538845</td>\n",
       "      <td>0.603417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4438.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10044.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15681.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21633.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id     essay_set  rater1_domain1  rater2_domain1  \\\n",
       "count  12976.000000  12976.000000    12976.000000    12976.000000   \n",
       "mean   10295.395808      4.179485        4.127158        4.137408   \n",
       "std     6309.074105      2.136913        4.212544        4.264330   \n",
       "min        1.000000      1.000000        0.000000        0.000000   \n",
       "25%     4438.750000      2.000000        2.000000        2.000000   \n",
       "50%    10044.500000      4.000000        3.000000        3.000000   \n",
       "75%    15681.250000      6.000000        4.000000        4.000000   \n",
       "max    21633.000000      8.000000       30.000000       30.000000   \n",
       "\n",
       "       rater3_domain1  domain1_score  rater1_domain2  rater2_domain2  \\\n",
       "count      128.000000   12976.000000     1800.000000     1800.000000   \n",
       "mean        37.828125       6.800247        3.333889        3.330556   \n",
       "std          5.240829       8.970705        0.729103        0.726807   \n",
       "min         20.000000       0.000000        1.000000        1.000000   \n",
       "25%         36.000000       2.000000        3.000000        3.000000   \n",
       "50%         40.000000       3.000000        3.000000        3.000000   \n",
       "75%         40.000000       8.000000        4.000000        4.000000   \n",
       "max         50.000000      60.000000        4.000000        4.000000   \n",
       "\n",
       "       domain2_score  rater1_trait1  ...  rater2_trait3  rater2_trait4  \\\n",
       "count    1800.000000    2292.000000  ...    2292.000000    2292.000000   \n",
       "mean        3.333889       2.444154  ...       2.635689       2.710297   \n",
       "std         0.729103       1.211730  ...       1.142566       1.045795   \n",
       "min         1.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         3.000000       2.000000  ...       2.000000       2.000000   \n",
       "50%         3.000000       2.000000  ...       2.000000       3.000000   \n",
       "75%         4.000000       3.000000  ...       4.000000       3.000000   \n",
       "max         4.000000       6.000000  ...       6.000000       6.000000   \n",
       "\n",
       "       rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "count     723.000000     723.000000     128.000000     128.000000   \n",
       "mean        3.777317       3.589212       3.945312       3.890625   \n",
       "std         0.689401       0.693256       0.643668       0.630390   \n",
       "min         1.000000       1.000000       2.000000       2.000000   \n",
       "25%         3.000000       3.000000       4.000000       4.000000   \n",
       "50%         4.000000       4.000000       4.000000       4.000000   \n",
       "75%         4.000000       4.000000       4.000000       4.000000   \n",
       "max         6.000000       6.000000       6.000000       6.000000   \n",
       "\n",
       "       rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "count     128.000000     128.000000     128.000000     128.000000  \n",
       "mean        4.078125       3.992188       3.843750       3.617188  \n",
       "std         0.622535       0.509687       0.538845       0.603417  \n",
       "min         2.000000       3.000000       2.000000       2.000000  \n",
       "25%         4.000000       4.000000       4.000000       3.000000  \n",
       "50%         4.000000       4.000000       4.000000       4.000000  \n",
       "75%         4.000000       4.000000       4.000000       4.000000  \n",
       "max         6.000000       6.000000       5.000000       5.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12976 entries, 0 to 12975\n",
      "Data columns (total 28 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   essay_id        12976 non-null  int64  \n",
      " 1   essay_set       12976 non-null  int64  \n",
      " 2   essay           12976 non-null  object \n",
      " 3   rater1_domain1  12976 non-null  int64  \n",
      " 4   rater2_domain1  12976 non-null  int64  \n",
      " 5   rater3_domain1  128 non-null    float64\n",
      " 6   domain1_score   12976 non-null  int64  \n",
      " 7   rater1_domain2  1800 non-null   float64\n",
      " 8   rater2_domain2  1800 non-null   float64\n",
      " 9   domain2_score   1800 non-null   float64\n",
      " 10  rater1_trait1   2292 non-null   float64\n",
      " 11  rater1_trait2   2292 non-null   float64\n",
      " 12  rater1_trait3   2292 non-null   float64\n",
      " 13  rater1_trait4   2292 non-null   float64\n",
      " 14  rater1_trait5   723 non-null    float64\n",
      " 15  rater1_trait6   723 non-null    float64\n",
      " 16  rater2_trait1   2292 non-null   float64\n",
      " 17  rater2_trait2   2292 non-null   float64\n",
      " 18  rater2_trait3   2292 non-null   float64\n",
      " 19  rater2_trait4   2292 non-null   float64\n",
      " 20  rater2_trait5   723 non-null    float64\n",
      " 21  rater2_trait6   723 non-null    float64\n",
      " 22  rater3_trait1   128 non-null    float64\n",
      " 23  rater3_trait2   128 non-null    float64\n",
      " 24  rater3_trait3   128 non-null    float64\n",
      " 25  rater3_trait4   128 non-null    float64\n",
      " 26  rater3_trait5   128 non-null    float64\n",
      " 27  rater3_trait6   128 non-null    float64\n",
      "dtypes: float64(22), int64(5), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FEATURES HAHAHAHA\n",
    "def calculate_features(text):\n",
    "    \"\"\"\n",
    "    Calcule une série de fonctionnalités linguistiques à partir d'un texte donné.\n",
    "    \"\"\"\n",
    "\n",
    "    # Préparation\n",
    "    words = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_counts = Counter(words)\n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(words)\n",
    "\n",
    "    # 0. Faute d'Orthographe\n",
    "\n",
    "    spell = SpellChecker(language='en')\n",
    "    misspelled = spell.unknown(words)\n",
    "    # Le nombre de mots mal orthographiés est le nombre de fautes d'orthographe\n",
    "    count_spelling_errors = len(misspelled)\n",
    "\n",
    "    # 1. Longueur du texte\n",
    "    text_length = len(text)\n",
    "\n",
    "    # 2. Nombre de phrases\n",
    "    num_sentences = len(sentences)\n",
    "\n",
    "    # 3. Nombre de mots\n",
    "    num_words = len(words)\n",
    "\n",
    "    # 4. Taille moyenne des mots\n",
    "    avg_word_length = sum(len(word) for word in words) / num_words\n",
    "\n",
    "    # 5. Nombre de mots uniques\n",
    "    num_unique_words = len(set(words))\n",
    "\n",
    "    # 6. Fréquence des mots de fonction\n",
    "    function_words = set(stopwords.words('english'))\n",
    "    function_word_frequency = sum(word_counts[word] for word in function_words)\n",
    "\n",
    "    # 7. Fréquence des mots de contenu\n",
    "    content_words = set(words) - function_words\n",
    "    content_word_frequency = sum(word_counts[word] for word in content_words)\n",
    "\n",
    "    # 9. Fréquence des erreurs d'orthographe\n",
    "    spelling_errors = len(misspelled)\n",
    "\n",
    "    # 10. Fréquence des erreurs de grammaire\n",
    "\n",
    "\n",
    "    # 11. Fréquence des mots positifs/négatifs\n",
    "    # Ceci nécessiterait une liste de mots positifs/négatifs\n",
    "    # Ici, nous utilisons le module NLTK's Vader qui a une liste intégrée de mots positifs et négatifs\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    positive_word_proportion = sentiment['pos']\n",
    "    negative_word_proportion = sentiment['neg']\n",
    "\n",
    "    # 12. Fréquence des entités nommées\n",
    "    # Ceci est plus complexe à calculer et nécessiterait une bibliothèque spécialisée\n",
    "    # Ici, nous utilisons la bibliothèque SpaCy qui a un bon support pour l'extraction d'entités nommées\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    named_entities = [ent.text for ent in doc.ents]\n",
    "    named_entity_frequency = len(named_entities)\n",
    "\n",
    "    # 13. Fréquence des citations\n",
    "    quote_frequency = text.count('\"') // 2\n",
    "\n",
    "    # 14. Fréquence des majuscules\n",
    "    uppercase_frequency = sum(1 for char in text if char.isupper())\n",
    "\n",
    "    # 15. Fréquence des signes de ponctuation\n",
    "    punctuation_marks = {'.', ',', '!', '?', ':', ';', '-', '(', ')', '[', ']', '{', '}', '\"', \"'\"}\n",
    "    punctuation_frequency = sum(text.count(mark) for mark in punctuation_marks)\n",
    "\n",
    "    # 16. Fréquence des adverbes\n",
    "    adverb_frequency = sum(1 for word, pos in pos_tag(words) if pos == 'RB')\n",
    "\n",
    "    # 17. Fréquence des verbes au passé\n",
    "    past_tense_verb_frequency = sum(1 for word, pos in pos_tag(words) if pos == 'VBD')\n",
    "\n",
    "    # 18. Fréquence des verbes au présent\n",
    "    present_tense_verb_frequency = sum(1 for word, pos in pos_tag(words) if pos in ('VB', 'VBG', 'VBP', 'VBZ'))\n",
    "\n",
    "    # 19. Fréquence des pronoms\n",
    "    pronoun_frequency = sum(1 for word, pos in pos_tag(words) if pos in ('PRP', 'PRP$', 'WP', 'WP$'))\n",
    "\n",
    "    # 20. Fréquence des conjonctions de coordination\n",
    "    coordinating_conjunction_frequency = sum(1 for word, pos in pos_tag(words) if pos == 'CC')\n",
    "\n",
    "    # 21. Fréquence des adjectifs : Les adjectifs modifient les noms et peuvent indiquer le style d’écriture.\n",
    "    tagged = pos_tag(word_tokenize(text))\n",
    "    adjective_frequency = sum(1 for word, pos in tagged if pos == 'JJ')\n",
    "\n",
    "    # 22. Fréquence des noms propres : Les noms propres sont des noms spécifiques à des personnes, des lieux, etc. Leur fréquence peut indiquer le sujet du texte.\n",
    "    tagged_np = pos_tag(word_tokenize(text))\n",
    "    proper_noun_frequency = sum(1 for word, pos in tagged_np if pos == 'NNP')\n",
    "\n",
    "    # 23. Fréquence des modaux : Les modaux sont des auxiliaires qui expriment la nécessité, la possibilité, la permission, etc. Leur fréquence peut indiquer le ton du texte.\n",
    "    tagged_mf = pos_tag(word_tokenize(text))\n",
    "    modal_frequency = sum(1 for word, pos in tagged_mf if pos == 'MD')\n",
    "\n",
    "    # 24. Fréquence des déterminants : Les déterminants sont des mots qui précèdent les noms pour indiquer leur référence. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_df = pos_tag(word_tokenize(text))\n",
    "    determiner_frequency = sum(1 for word, pos in tagged_df if pos == 'DT')\n",
    "\n",
    "    # 25. Fréquence des prépositions : Les prépositions relient les noms, les pronoms et les phrases à d’autres mots dans une phrase. Leur fréquence peut indiquer la complexité de la structure des phrases.\n",
    "    tagged_pf = pos_tag(word_tokenize(text))\n",
    "    preposition_frequency = sum(1 for word, pos in tagged_pf if pos == 'IN')\n",
    "\n",
    "    # 26. Fréquence des pronoms interrogatifs : Les pronoms interrogatifs introduisent des questions. Leur fréquence peut indiquer si le texte contient beaucoup de questions.\n",
    "    tagged_ipf = pos_tag(word_tokenize(text))\n",
    "    interrogative_pronoun_frequency = sum(1 for word, pos in tagged_ipf if pos in ('WP', 'WP$'))\n",
    "\n",
    "    # 27. Fréquence des adverbes interrogatifs : Les adverbes interrogatifs introduisent des questions. Leur fréquence peut indiquer si le texte contient beaucoup de questions.\n",
    "    tagged_iaf = pos_tag(word_tokenize(text))\n",
    "    interrogative_adverb_frequency = sum(1 for word, pos in tagged_iaf if pos == 'WRB')\n",
    "\n",
    "    # 28. Fréquence des adverbes de négation : Les adverbes de négation expriment une négation. Leur fréquence peut indiquer le ton du texte\n",
    "    tagged_naf = pos_tag(word_tokenize(text))\n",
    "    negation_adverb_frequency = sum(1 for word, pos in tagged_naf if word in ('not', 'never', 'no'))\n",
    "\n",
    "    # 29. Fréquence des adverbes de degré : Les adverbes de degré modifient les adjectifs et les adverbes pour indiquer le degré. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_daf = pos_tag(word_tokenize(text))\n",
    "    degree_adverb_frequency = sum(1 for word, pos in tagged_daf if word in ('very', 'too', 'so', 'quite', 'pretty', 'rather', 'somewhat', 'fairly'))\n",
    "\n",
    "    # 30. Fréquence des adverbes de manière : Les adverbes de manière décrivent la manière dont une action est effectuée. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_maf = pos_tag(word_tokenize(text))\n",
    "    manner_adverb_frequency = sum(1 for word, pos in tagged_maf if pos == 'RB' and word.endswith('ly'))\n",
    "\n",
    "    # 31. Fréquence des pronoms démonstratifs : Les pronoms démonstratifs indiquent des entités spécifiques. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_dpf = pos_tag(word_tokenize(text))\n",
    "    demonstrative_pronoun_frequency = sum(1 for word, pos in tagged_dpf if word in ('this', 'that', 'these', 'those'))\n",
    "\n",
    "    # 32. Fréquence des pronoms possessifs : Les pronoms possessifs indiquent la possession. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_ppf = pos_tag(word_tokenize(text))\n",
    "    possessive_pronoun_frequency = sum(1 for word, pos in tagged_ppf if word in ('my', 'your', 'his', 'her', 'its', 'our', 'their'))\n",
    "\n",
    "    # 33. Fréquence des pronoms réfléchis : Les pronoms réfléchis renvoient à d’autres entités dans la phrase. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_rpf = pos_tag(word_tokenize(text))\n",
    "    reflexive_pronoun_frequency = sum(1 for word, pos in tagged_rpf if word in ('myself', 'yourself', 'himself', 'herself', 'itself', 'ourselves', 'yourselves', 'themselves'))\n",
    "\n",
    "    # 34. Fréquence des pronoms réciproques : Les pronoms réciproques indiquent une action mutuelle. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_rpf2 = pos_tag(word_tokenize(text))\n",
    "    reciprocal_pronoun_frequency = sum(1 for word, pos in tagged_rpf2 if word in ('each other', 'one another'))\n",
    "\n",
    "    # 35. Fréquence des pronoms indéfinis : Les pronoms indéfinis ne renvoient pas à des entités spécifiques. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_ipf2 = pos_tag(word_tokenize(text))\n",
    "    indefinite_pronoun_frequency = sum(1 for word, pos in tagged_ipf2 if word in ('all', 'another', 'any', 'anybody', 'anyone', 'anything', 'each', 'everybody', 'everyone', 'everything', 'few', 'many', 'nobody', 'none', 'nothing', 'one', 'several', 'some', 'somebody', 'someone', 'something'))\n",
    "    \n",
    "    # 36. Fréquence des adjectifs possessifs : Les adjectifs possessifs indiquent la possession. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_af = pos_tag(word_tokenize(text))\n",
    "    possessive_adjective_frequency = sum(1 for word, pos in tagged_af if word in ('my', 'your', 'his', 'her', 'its', 'our', 'their'))\n",
    "\n",
    "    # 37. Fréquence des adjectifs démonstratifs : Les adjectifs démonstratifs indiquent des entités spécifiques. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_daf2 = pos_tag(word_tokenize(text))\n",
    "    demonstrative_adjective_frequency = sum(1 for word, pos in tagged_daf2 if word in ('this', 'that', 'these', 'those'))\n",
    "\n",
    "    # 38. Fréquence des adjectifs indéfinis : Les adjectifs indéfinis ne renvoient pas à des entités spécifiques. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_iaf2 = pos_tag(word_tokenize(text))\n",
    "    indefinite_adjective_frequency = sum(1 for word, pos in tagged_iaf2 if word in ('all', 'another', 'any', 'both', 'each', 'few', 'many', 'several', 'some'))\n",
    "\n",
    "    # 39. Fréquence des adjectifs interrogatifs : Les adjectifs interrogatifs introduisent des questions. Leur fréquence peut indiquer si le texte contient beaucoup de questions.\n",
    "    tagged_iaf3 = pos_tag(word_tokenize(text))\n",
    "    interrogative_adjective_frequency = sum(1 for word, pos in tagged_iaf3 if word in ('which', 'what', 'whose'))\n",
    "\n",
    "    # 40. Fréquence des adjectifs exclamatifs : Les adjectifs exclamatifs expriment une émotion ou une réaction. Leur fréquence peut indiquer le ton du texte.\n",
    "    tagged_eaf = pos_tag(word_tokenize(text))\n",
    "    exclamatory_adjective_frequency = sum(1 for word, pos in tagged_eaf if word in ('what', 'such'))\n",
    "\n",
    "    # 41. Fréquence des verbes auxiliaires : Les verbes auxiliaires sont utilisés avec d’autres verbes pour indiquer le temps, la voix, l’humeur, etc. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_avf = pos_tag(word_tokenize(text))\n",
    "    auxiliary_verb_frequency = sum(1 for word, pos in tagged_avf if word in ('be', 'have', 'do', 'can', 'could', 'may', 'might', 'must', 'shall', 'should', 'will', 'would'))\n",
    "\n",
    "    # 42. Fréquence des verbes modaux : Les verbes modaux expriment la nécessité, la possibilité, la permission, etc. Leur fréquence peut indiquer le ton du texte.\n",
    "    tagged_mvf = pos_tag(word_tokenize(text))\n",
    "    modal_verb_frequency = sum(1 for word, pos in tagged_mvf if word in ('can', 'could', 'may', 'might', 'must', 'shall', 'should', 'will', 'would'))\n",
    "    \n",
    "    # 43. Fréquence des adverbes modificateurs : Les adverbes modificateurs modifient les adjectifs et les adverbes pour indiquer le degré. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_maf2 = pos_tag(word_tokenize(text))\n",
    "    modifier_adverb_frequency = sum(1 for word, pos in tagged_maf2 if word in ('very', 'too', 'so', 'quite', 'pretty', 'rather', 'somewhat', 'fairly'))\n",
    "\n",
    "    # 44. Fréquence des adverbes de liaison : Les adverbes de liaison introduisent une phrase ou une clause. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_laf = pos_tag(word_tokenize(text))\n",
    "    linking_adverb_frequency = sum(1 for word, pos in tagged_laf if word in ('however', 'therefore', 'consequently', 'meanwhile', 'furthermore', 'otherwise'))\n",
    "\n",
    "    # 45. Fréquence des adverbes de négation : Les adverbes de négation expriment une négation. Leur fréquence peut indiquer le ton du texte.\n",
    "    tagged_naf2 = pos_tag(word_tokenize(text))\n",
    "    negation_adverb_frequency = sum(1 for word, pos in tagged_naf2 if word in ('not', 'never', 'no'))\n",
    "\n",
    "    # 46. Fréquence des adverbes de degré : Les adverbes de degré modifient les adjectifs et les adverbes pour indiquer le degré. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_daf3 = pos_tag(word_tokenize(text))\n",
    "    degree_adverb_frequency = sum(1 for word, pos in tagged_daf3 if word in ('very', 'too', 'so', 'quite', 'pretty', 'rather', 'somewhat', 'fairly'))\n",
    "\n",
    "    # 47. Fréquence des adverbes de manière : Les adverbes de manière décrivent la manière dont une action est effectuée. Leur fréquence peut indiquer le style d’écriture.\n",
    "    tagged_maf3 = pos_tag(word_tokenize(text))\n",
    "    manner_adverb_frequency = sum(1 for word, pos in tagged_maf3 if pos == 'RB' and word.endswith('ly'))\n",
    "\n",
    "    # 48. Fréquence des adverbes de lieu : Les adverbes de lieu indiquent le lieu d’une action. Leur fréquence peut indiquer le sujet du texte.\n",
    "    tagged_paf = pos_tag(word_tokenize(text))\n",
    "    place_adverb_frequency = sum(1 for word, pos in tagged_paf if word in ('here', 'there', 'everywhere', 'somewhere', 'anywhere', 'nowhere'))\n",
    "\n",
    "    # 49. Fréquence des conjonctions de coordination : Les conjonctions de coordination relient des mots, des phrases ou des clauses de même importance. Leur fréquence peut indiquer la complexité de la structure des phrases.\n",
    "    tagged_ccf = pos_tag(word_tokenize(text))\n",
    "    coordinating_conjunction_frequency = sum(1 for word, pos in tagged_ccf if word in ('and', 'but', 'or', 'so', 'yet', 'for', 'nor'))\n",
    "\n",
    "    # 50. Fréquence des conjonctions de subordination : Les conjonctions de subordination relient une clause subordonnée à une clause principale. Leur fréquence peut indiquer la complexité de la structure des phrases.\n",
    "    tagged_scf = pos_tag(word_tokenize(text))\n",
    "    subordinating_conjunction_frequency = sum(1 for word, pos in tagged_scf if word in ('although', 'because', 'if', 'unless', 'while', 'though', 'whereas', 'as', 'since', 'when', 'until', 'after', 'before'))\n",
    "\n",
    "    # 51. Fréquence des conjonctions corrélatives : Les conjonctions corrélatives travaillent en paires pour relier des mots, des phrases ou des clauses de même importance. Leur fréquence peut indiquer la complexité de la structure des phrases.\n",
    "    tagged_ccf2 = pos_tag(word_tokenize(text))\n",
    "    correlative_conjunction_frequency = sum(1 for word, pos in tagged_ccf2 if word in ('either', 'or', 'neither', 'nor', 'not only', 'but also', 'whether', 'or', 'as', 'as', 'so', 'as'))\n",
    "\n",
    "    # 52. Fréquence des interjections : Les interjections sont des mots ou des expressions qui expriment une émotion ou une réaction. Leur fréquence peut indiquer le ton du texte.\n",
    "    tagged_if = pos_tag(word_tokenize(text))\n",
    "    interjection_frequency = sum(1 for word, pos in tagged_if if pos == 'UH')\n",
    "\n",
    "    # 53. Fréquence des onomatopées : Les onomatopées sont des mots qui imitent les sons. Leur fréquence peut indiquer le sujet du texte.\n",
    "    tagged_of = pos_tag(word_tokenize(text))\n",
    "    onomatopoeia_frequency = sum(1 for word, pos in tagged_of if word in ('bang', 'beep', 'buzz', 'click', 'ding', 'hiss', 'pop', 'sizzle', 'snap', 'whack', 'whoosh', 'zip', 'clank', 'clang', 'creak', 'crunch', 'gulp', 'jingle', 'jangle', 'rattle', 'snore', 'sniff', 'snort', 'squeak', 'swoosh', 'thud', 'toot', 'twang', 'yelp', 'zing', 'boing', 'zap', 'pow', 'zip', 'swish', 'splash', 'crash', 'chirp', 'tweet', 'honk', 'vroom', 'beep', 'zoom', 'giggle', 'murmur', 'moo', 'oink', 'quack'))\n",
    "\n",
    "    # 54. Fréquence des palindromes : Les palindromes sont des mots qui se lisent de la même manière de gauche à droite et de droite à gauche. Leur fréquence peut indiquer le style d’écriture.\n",
    "    words = text.split()\n",
    "    palindrome_frequency = sum(1 for word in words if word == word[::-1])\n",
    "\n",
    "    return {\n",
    "        'count_spelling_errors' : count_spelling_errors,\n",
    "        'text_length': text_length,\n",
    "        'num_sentences': num_sentences,\n",
    "        'num_words': num_words,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'num_unique_words': num_unique_words,\n",
    "        'function_word_frequency': function_word_frequency,\n",
    "        'content_word_frequency': content_word_frequency,\n",
    "        'spelling_errors': spelling_errors,\n",
    "        'quote_frequency': quote_frequency,\n",
    "        'uppercase_frequency': uppercase_frequency,\n",
    "        'punctuation_frequency': punctuation_frequency,\n",
    "        'adverb_frequency': adverb_frequency,\n",
    "        'past_tense_verb_frequency': past_tense_verb_frequency,\n",
    "        'present_tense_verb_frequency': present_tense_verb_frequency,\n",
    "        'pronoun_frequency': pronoun_frequency,\n",
    "        'coordinating_conjunction_frequency': coordinating_conjunction_frequency,\n",
    "        'negative_word_proportion' : negative_word_proportion,\n",
    "        'named_entity_frequency': named_entity_frequency,\n",
    "        'adjective_frequency': adjective_frequency,\n",
    "        'proper_noun_frequency' : proper_noun_frequency,\n",
    "        'modal_frequency' : modal_frequency,\n",
    "        'determiner_frequency' : determiner_frequency,\n",
    "        'interrogative_adverb_frequency' : interrogative_adverb_frequency,\n",
    "        'interrogative_pronoun_frequency' : interrogative_pronoun_frequency,\n",
    "        'preposition_frequency' : preposition_frequency,\n",
    "        'negation_adverb_frequency' : negation_adverb_frequency,\n",
    "        'degree_adverb_frequency' : degree_adverb_frequency,\n",
    "        'manner_adverb_frequency' : manner_adverb_frequency,\n",
    "        'demonstrative_pronoun_frequency' : demonstrative_pronoun_frequency,\n",
    "        'possessive_pronoun_frequency' : possessive_pronoun_frequency,\n",
    "        'reflexive_pronoun_frequency' : reflexive_pronoun_frequency,\n",
    "        'reciprocal_pronoun_frequency' : reciprocal_pronoun_frequency,\n",
    "        'indefinite_pronoun_frequency' : indefinite_pronoun_frequency,\n",
    "        'possessive_adjective_frequency' : possessive_adjective_frequency,\n",
    "        'demonstrative_adjective_frequency' : demonstrative_adjective_frequency,\n",
    "        'indefinite_adjective_frequency' : indefinite_adjective_frequency,\n",
    "        'interrogative_adjective_frequency' : interrogative_adjective_frequency,\n",
    "        'exclamatory_adjective_frequency' : exclamatory_adjective_frequency,\n",
    "        'auxiliary_verb_frequency' : auxiliary_verb_frequency,\n",
    "        'modal_verb_frequency' : modal_verb_frequency,\n",
    "        'modifier_adverb_frequency' : modifier_adverb_frequency,\n",
    "        'linking_adverb_frequency' : linking_adverb_frequency,\n",
    "        'negation_adverb_frequency' : negation_adverb_frequency,\n",
    "        'degree_adverb_frequency' : degree_adverb_frequency,\n",
    "        'manner_adverb_frequency' : manner_adverb_frequency,\n",
    "        'place_adverb_frequency' : place_adverb_frequency,\n",
    "        'coordinating_conjunction_frequency' : coordinating_conjunction_frequency,\n",
    "        'subordinating_conjunction_frequency' : subordinating_conjunction_frequency,\n",
    "        'correlative_conjunction_frequency' : correlative_conjunction_frequency,\n",
    "        'interjection_frequency' : interjection_frequency,\n",
    "        'onomatopoeia_frequency' : onomatopoeia_frequency,\n",
    "        'palindrome_frequency' : palindrome_frequency,\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dear, @CAPS1 @CAPS2 @CAPS3 More and more people use computers, but not everyone agrees that this benefits society. Those who support advances in technology believe that computers have a positive effect on people. Others have different ideas. A great amount in the world today are using computers, some for work and spme for the fun of it. Computers is one of mans greatest accomplishments. Computers are helpful in so many ways, @CAPS4, news, and live streams. Don't get me wrong way to much people spend time on the computer and they should be out interacting with others but who are we to tell them what to do. When I grow up I want to be a author or a journalist and I know for a fact that both of those jobs involve lots of time on time on the computer, one @MONTH1 spend more time then the other but you know exactly what @CAPS5 getting at. So what if some expert think people are spending to much time on the computer and not exercising, enjoying natures and interacting with family and friends. For all the expert knows that its how must people make a living and we don't know why people choose to use the computer for a great amount of time and to be honest it's non of my concern and it shouldn't be the so called experts concern. People interact a thousand times a day on the computers. Computers keep lots of kids of the streets instead of being out and causing trouble. Computers helps the @ORGANIZATION1 locate most wanted criminals. As you can see computers are more useful to society then you think, computers benefit society.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifions un essai\n",
    "df_training_set['essay'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count_spelling_errors': 10,\n",
       " 'text_length': 1541,\n",
       " 'num_sentences': 14,\n",
       " 'num_words': 313,\n",
       " 'avg_word_length': 4.035143769968051,\n",
       " 'num_unique_words': 161,\n",
       " 'function_word_frequency': 132,\n",
       " 'content_word_frequency': 181,\n",
       " 'spelling_errors': 10,\n",
       " 'quote_frequency': 0,\n",
       " 'uppercase_frequency': 55,\n",
       " 'punctuation_frequency': 27,\n",
       " 'adverb_frequency': 11,\n",
       " 'past_tense_verb_frequency': 1,\n",
       " 'present_tense_verb_frequency': 52,\n",
       " 'pronoun_frequency': 21,\n",
       " 'coordinating_conjunction_frequency': 22,\n",
       " 'negative_word_proportion': 0.045,\n",
       " 'named_entity_frequency': 5,\n",
       " 'adjective_frequency': 15,\n",
       " 'proper_noun_frequency': 13,\n",
       " 'modal_frequency': 4,\n",
       " 'determiner_frequency': 27,\n",
       " 'interrogative_adverb_frequency': 3,\n",
       " 'interrogative_pronoun_frequency': 5,\n",
       " 'preposition_frequency': 32,\n",
       " 'negation_adverb_frequency': 2,\n",
       " 'degree_adverb_frequency': 2,\n",
       " 'manner_adverb_frequency': 1,\n",
       " 'demonstrative_pronoun_frequency': 6,\n",
       " 'possessive_pronoun_frequency': 2,\n",
       " 'reflexive_pronoun_frequency': 0,\n",
       " 'reciprocal_pronoun_frequency': 0,\n",
       " 'indefinite_pronoun_frequency': 7,\n",
       " 'possessive_adjective_frequency': 2,\n",
       " 'demonstrative_adjective_frequency': 6,\n",
       " 'indefinite_adjective_frequency': 5,\n",
       " 'interrogative_adjective_frequency': 3,\n",
       " 'exclamatory_adjective_frequency': 3,\n",
       " 'auxiliary_verb_frequency': 12,\n",
       " 'modal_verb_frequency': 4,\n",
       " 'modifier_adverb_frequency': 2,\n",
       " 'linking_adverb_frequency': 0,\n",
       " 'place_adverb_frequency': 0,\n",
       " 'subordinating_conjunction_frequency': 1,\n",
       " 'correlative_conjunction_frequency': 3,\n",
       " 'interjection_frequency': 0,\n",
       " 'onomatopoeia_frequency': 0,\n",
       " 'palindrome_frequency': 13}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test de la fonction\n",
    "calculate_features(df_training_set['essay'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prendre un echantillon pour appliquez la fonction\n",
    "# df_test = df_training_set.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test application de ma fonction \n",
    "# result_df2 = df_test['essay'].apply((lambda x: pd.Series(calculate_features(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la fonction sur le df_training_set\n",
    "result_df = df_training_set['essay'].apply((lambda x: pd.Series(calculate_features(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12976 entries, 0 to 12975\n",
      "Data columns (total 50 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   count_spelling_errors                12976 non-null  int64  \n",
      " 1   text_length                          12976 non-null  int64  \n",
      " 2   num_sentences                        12976 non-null  int64  \n",
      " 3   num_words                            12976 non-null  int64  \n",
      " 4   avg_word_length                      12976 non-null  float64\n",
      " 5   num_unique_words                     12976 non-null  int64  \n",
      " 6   function_word_frequency              12976 non-null  int64  \n",
      " 7   content_word_frequency               12976 non-null  int64  \n",
      " 8   ngram_counts                         12976 non-null  object \n",
      " 9   spelling_errors                      12976 non-null  int64  \n",
      " 10  quote_frequency                      12976 non-null  int64  \n",
      " 11  uppercase_frequency                  12976 non-null  int64  \n",
      " 12  punctuation_frequency                12976 non-null  int64  \n",
      " 13  adverb_frequency                     12976 non-null  int64  \n",
      " 14  past_tense_verb_frequency            12976 non-null  int64  \n",
      " 15  present_tense_verb_frequency         12976 non-null  int64  \n",
      " 16  pronoun_frequency                    12976 non-null  int64  \n",
      " 17  coordinating_conjunction_frequency   12976 non-null  int64  \n",
      " 18  negative_word_proportion             12976 non-null  float64\n",
      " 19  named_entity_frequency               12976 non-null  int64  \n",
      " 20  adjective_frequency                  12976 non-null  int64  \n",
      " 21  proper_noun_frequency                12976 non-null  int64  \n",
      " 22  modal_frequency                      12976 non-null  int64  \n",
      " 23  determiner_frequency                 12976 non-null  int64  \n",
      " 24  interrogative_adverb_frequency       12976 non-null  int64  \n",
      " 25  interrogative_pronoun_frequency      12976 non-null  int64  \n",
      " 26  preposition_frequency                12976 non-null  int64  \n",
      " 27  negation_adverb_frequency            12976 non-null  int64  \n",
      " 28  degree_adverb_frequency              12976 non-null  int64  \n",
      " 29  manner_adverb_frequency              12976 non-null  int64  \n",
      " 30  demonstrative_pronoun_frequency      12976 non-null  int64  \n",
      " 31  possessive_pronoun_frequency         12976 non-null  int64  \n",
      " 32  reflexive_pronoun_frequency          12976 non-null  int64  \n",
      " 33  reciprocal_pronoun_frequency         12976 non-null  int64  \n",
      " 34  indefinite_pronoun_frequency         12976 non-null  int64  \n",
      " 35  possessive_adjective_frequency       12976 non-null  int64  \n",
      " 36  demonstrative_adjective_frequency    12976 non-null  int64  \n",
      " 37  indefinite_adjective_frequency       12976 non-null  int64  \n",
      " 38  interrogative_adjective_frequency    12976 non-null  int64  \n",
      " 39  exclamatory_adjective_frequency      12976 non-null  int64  \n",
      " 40  auxiliary_verb_frequency             12976 non-null  int64  \n",
      " 41  modal_verb_frequency                 12976 non-null  int64  \n",
      " 42  modifier_adverb_frequency            12976 non-null  int64  \n",
      " 43  linking_adverb_frequency             12976 non-null  int64  \n",
      " 44  place_adverb_frequency               12976 non-null  int64  \n",
      " 45  subordinating_conjunction_frequency  12976 non-null  int64  \n",
      " 46  correlative_conjunction_frequency    12976 non-null  int64  \n",
      " 47  interjection_frequency               12976 non-null  int64  \n",
      " 48  onomatopoeia_frequency               12976 non-null  int64  \n",
      " 49  palindrome_frequency                 12976 non-null  int64  \n",
      "dtypes: float64(2), int64(47), object(1)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# check resultat_df\n",
    "result_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_spelling_errors</th>\n",
       "      <th>text_length</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>function_word_frequency</th>\n",
       "      <th>content_word_frequency</th>\n",
       "      <th>spelling_errors</th>\n",
       "      <th>quote_frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>auxiliary_verb_frequency</th>\n",
       "      <th>modal_verb_frequency</th>\n",
       "      <th>modifier_adverb_frequency</th>\n",
       "      <th>linking_adverb_frequency</th>\n",
       "      <th>place_adverb_frequency</th>\n",
       "      <th>subordinating_conjunction_frequency</th>\n",
       "      <th>correlative_conjunction_frequency</th>\n",
       "      <th>interjection_frequency</th>\n",
       "      <th>onomatopoeia_frequency</th>\n",
       "      <th>palindrome_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.471332</td>\n",
       "      <td>1216.011714</td>\n",
       "      <td>12.776896</td>\n",
       "      <td>252.479732</td>\n",
       "      <td>3.963150</td>\n",
       "      <td>119.017494</td>\n",
       "      <td>103.158061</td>\n",
       "      <td>149.321671</td>\n",
       "      <td>9.471332</td>\n",
       "      <td>0.665613</td>\n",
       "      <td>...</td>\n",
       "      <td>9.093866</td>\n",
       "      <td>4.524199</td>\n",
       "      <td>1.595330</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>3.886252</td>\n",
       "      <td>2.870916</td>\n",
       "      <td>0.063579</td>\n",
       "      <td>0.039997</td>\n",
       "      <td>9.256936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.911122</td>\n",
       "      <td>958.322588</td>\n",
       "      <td>11.192549</td>\n",
       "      <td>203.361983</td>\n",
       "      <td>0.341754</td>\n",
       "      <td>70.975526</td>\n",
       "      <td>84.125189</td>\n",
       "      <td>122.222254</td>\n",
       "      <td>7.911122</td>\n",
       "      <td>1.659401</td>\n",
       "      <td>...</td>\n",
       "      <td>10.378990</td>\n",
       "      <td>5.229341</td>\n",
       "      <td>2.048094</td>\n",
       "      <td>0.219426</td>\n",
       "      <td>1.549965</td>\n",
       "      <td>3.838976</td>\n",
       "      <td>3.665249</td>\n",
       "      <td>0.288047</td>\n",
       "      <td>0.243330</td>\n",
       "      <td>10.655898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.014286</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>3.764408</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>3.981613</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>1670.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>4.178964</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>6098.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1204.000000</td>\n",
       "      <td>15.285714</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>537.000000</td>\n",
       "      <td>925.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       count_spelling_errors   text_length  num_sentences     num_words  \\\n",
       "count           12976.000000  12976.000000   12976.000000  12976.000000   \n",
       "mean                9.471332   1216.011714      12.776896    252.479732   \n",
       "std                 7.911122    958.322588      11.192549    203.361983   \n",
       "min                 0.000000      8.000000       1.000000      2.000000   \n",
       "25%                 4.000000    527.000000       5.000000    109.000000   \n",
       "50%                 8.000000    901.000000       9.000000    184.000000   \n",
       "75%                13.000000   1670.000000      18.000000    348.000000   \n",
       "max               101.000000   6098.000000      96.000000   1204.000000   \n",
       "\n",
       "       avg_word_length  num_unique_words  function_word_frequency  \\\n",
       "count     12976.000000      12976.000000             12976.000000   \n",
       "mean          3.963150        119.017494               103.158061   \n",
       "std           0.341754         70.975526                84.125189   \n",
       "min           2.014286          2.000000                 0.000000   \n",
       "25%           3.764408         67.000000                45.000000   \n",
       "50%           3.981613        102.000000                73.000000   \n",
       "75%           4.178964        155.000000               143.000000   \n",
       "max          15.285714        506.000000               537.000000   \n",
       "\n",
       "       content_word_frequency  spelling_errors  quote_frequency  ...  \\\n",
       "count            12976.000000     12976.000000     12976.000000  ...   \n",
       "mean               149.321671         9.471332         0.665613  ...   \n",
       "std                122.222254         7.911122         1.659401  ...   \n",
       "min                  2.000000         0.000000         0.000000  ...   \n",
       "25%                 63.000000         4.000000         0.000000  ...   \n",
       "50%                110.000000         8.000000         0.000000  ...   \n",
       "75%                202.000000        13.000000         1.000000  ...   \n",
       "max                925.000000       101.000000        45.000000  ...   \n",
       "\n",
       "       auxiliary_verb_frequency  modal_verb_frequency  \\\n",
       "count              12976.000000          12976.000000   \n",
       "mean                   9.093866              4.524199   \n",
       "std                   10.378990              5.229341   \n",
       "min                    0.000000              0.000000   \n",
       "25%                    2.000000              1.000000   \n",
       "50%                    5.000000              3.000000   \n",
       "75%                   14.000000              7.000000   \n",
       "max                   94.000000             50.000000   \n",
       "\n",
       "       modifier_adverb_frequency  linking_adverb_frequency  \\\n",
       "count               12976.000000              12976.000000   \n",
       "mean                    1.595330                  0.039535   \n",
       "std                     2.048094                  0.219426   \n",
       "min                     0.000000                  0.000000   \n",
       "25%                     0.000000                  0.000000   \n",
       "50%                     1.000000                  0.000000   \n",
       "75%                     2.000000                  0.000000   \n",
       "max                    26.000000                  4.000000   \n",
       "\n",
       "       place_adverb_frequency  subordinating_conjunction_frequency  \\\n",
       "count            12976.000000                         12976.000000   \n",
       "mean                 0.982506                             3.886252   \n",
       "std                  1.549965                             3.838976   \n",
       "min                  0.000000                             0.000000   \n",
       "25%                  0.000000                             1.000000   \n",
       "50%                  0.000000                             3.000000   \n",
       "75%                  1.000000                             5.000000   \n",
       "max                 21.000000                            36.000000   \n",
       "\n",
       "       correlative_conjunction_frequency  interjection_frequency  \\\n",
       "count                       12976.000000            12976.000000   \n",
       "mean                            2.870916                0.063579   \n",
       "std                             3.665249                0.288047   \n",
       "min                             0.000000                0.000000   \n",
       "25%                             0.000000                0.000000   \n",
       "50%                             2.000000                0.000000   \n",
       "75%                             4.000000                0.000000   \n",
       "max                            30.000000                5.000000   \n",
       "\n",
       "       onomatopoeia_frequency  palindrome_frequency  \n",
       "count            12976.000000          12976.000000  \n",
       "mean                 0.039997              9.256936  \n",
       "std                  0.243330             10.655898  \n",
       "min                  0.000000              0.000000  \n",
       "25%                  0.000000              2.000000  \n",
       "50%                  0.000000              5.000000  \n",
       "75%                  0.000000             13.000000  \n",
       "max                  5.000000            100.000000  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_training_set \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_training_set,\u001b[43mresult_df\u001b[49m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m new_training_set\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "new_training_set = pd.concat([df_training_set,result_df],axis=1)\n",
    "new_training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>rater1_trait1</th>\n",
       "      <th>...</th>\n",
       "      <th>auxiliary_verb_frequency</th>\n",
       "      <th>modal_verb_frequency</th>\n",
       "      <th>modifier_adverb_frequency</th>\n",
       "      <th>linking_adverb_frequency</th>\n",
       "      <th>place_adverb_frequency</th>\n",
       "      <th>subordinating_conjunction_frequency</th>\n",
       "      <th>correlative_conjunction_frequency</th>\n",
       "      <th>interjection_frequency</th>\n",
       "      <th>onomatopoeia_frequency</th>\n",
       "      <th>palindrome_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10295.395808</td>\n",
       "      <td>4.179485</td>\n",
       "      <td>4.127158</td>\n",
       "      <td>4.137408</td>\n",
       "      <td>37.828125</td>\n",
       "      <td>6.800247</td>\n",
       "      <td>3.333889</td>\n",
       "      <td>3.330556</td>\n",
       "      <td>3.333889</td>\n",
       "      <td>2.444154</td>\n",
       "      <td>...</td>\n",
       "      <td>9.093866</td>\n",
       "      <td>4.524199</td>\n",
       "      <td>1.595330</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.982506</td>\n",
       "      <td>3.886252</td>\n",
       "      <td>2.870916</td>\n",
       "      <td>0.063579</td>\n",
       "      <td>0.039997</td>\n",
       "      <td>9.256936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6309.074105</td>\n",
       "      <td>2.136913</td>\n",
       "      <td>4.212544</td>\n",
       "      <td>4.264330</td>\n",
       "      <td>5.240829</td>\n",
       "      <td>8.970705</td>\n",
       "      <td>0.729103</td>\n",
       "      <td>0.726807</td>\n",
       "      <td>0.729103</td>\n",
       "      <td>1.211730</td>\n",
       "      <td>...</td>\n",
       "      <td>10.378990</td>\n",
       "      <td>5.229341</td>\n",
       "      <td>2.048094</td>\n",
       "      <td>0.219426</td>\n",
       "      <td>1.549965</td>\n",
       "      <td>3.838976</td>\n",
       "      <td>3.665249</td>\n",
       "      <td>0.288047</td>\n",
       "      <td>0.243330</td>\n",
       "      <td>10.655898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4438.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10044.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15681.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21633.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           essay_id     essay_set  rater1_domain1  rater2_domain1  \\\n",
       "count  12976.000000  12976.000000    12976.000000    12976.000000   \n",
       "mean   10295.395808      4.179485        4.127158        4.137408   \n",
       "std     6309.074105      2.136913        4.212544        4.264330   \n",
       "min        1.000000      1.000000        0.000000        0.000000   \n",
       "25%     4438.750000      2.000000        2.000000        2.000000   \n",
       "50%    10044.500000      4.000000        3.000000        3.000000   \n",
       "75%    15681.250000      6.000000        4.000000        4.000000   \n",
       "max    21633.000000      8.000000       30.000000       30.000000   \n",
       "\n",
       "       rater3_domain1  domain1_score  rater1_domain2  rater2_domain2  \\\n",
       "count      128.000000   12976.000000     1800.000000     1800.000000   \n",
       "mean        37.828125       6.800247        3.333889        3.330556   \n",
       "std          5.240829       8.970705        0.729103        0.726807   \n",
       "min         20.000000       0.000000        1.000000        1.000000   \n",
       "25%         36.000000       2.000000        3.000000        3.000000   \n",
       "50%         40.000000       3.000000        3.000000        3.000000   \n",
       "75%         40.000000       8.000000        4.000000        4.000000   \n",
       "max         50.000000      60.000000        4.000000        4.000000   \n",
       "\n",
       "       domain2_score  rater1_trait1  ...  auxiliary_verb_frequency  \\\n",
       "count    1800.000000    2292.000000  ...              12976.000000   \n",
       "mean        3.333889       2.444154  ...                  9.093866   \n",
       "std         0.729103       1.211730  ...                 10.378990   \n",
       "min         1.000000       0.000000  ...                  0.000000   \n",
       "25%         3.000000       2.000000  ...                  2.000000   \n",
       "50%         3.000000       2.000000  ...                  5.000000   \n",
       "75%         4.000000       3.000000  ...                 14.000000   \n",
       "max         4.000000       6.000000  ...                 94.000000   \n",
       "\n",
       "       modal_verb_frequency  modifier_adverb_frequency  \\\n",
       "count          12976.000000               12976.000000   \n",
       "mean               4.524199                   1.595330   \n",
       "std                5.229341                   2.048094   \n",
       "min                0.000000                   0.000000   \n",
       "25%                1.000000                   0.000000   \n",
       "50%                3.000000                   1.000000   \n",
       "75%                7.000000                   2.000000   \n",
       "max               50.000000                  26.000000   \n",
       "\n",
       "       linking_adverb_frequency  place_adverb_frequency  \\\n",
       "count              12976.000000            12976.000000   \n",
       "mean                   0.039535                0.982506   \n",
       "std                    0.219426                1.549965   \n",
       "min                    0.000000                0.000000   \n",
       "25%                    0.000000                0.000000   \n",
       "50%                    0.000000                0.000000   \n",
       "75%                    0.000000                1.000000   \n",
       "max                    4.000000               21.000000   \n",
       "\n",
       "       subordinating_conjunction_frequency  correlative_conjunction_frequency  \\\n",
       "count                         12976.000000                       12976.000000   \n",
       "mean                              3.886252                           2.870916   \n",
       "std                               3.838976                           3.665249   \n",
       "min                               0.000000                           0.000000   \n",
       "25%                               1.000000                           0.000000   \n",
       "50%                               3.000000                           2.000000   \n",
       "75%                               5.000000                           4.000000   \n",
       "max                              36.000000                          30.000000   \n",
       "\n",
       "       interjection_frequency  onomatopoeia_frequency  palindrome_frequency  \n",
       "count            12976.000000            12976.000000          12976.000000  \n",
       "mean                 0.063579                0.039997              9.256936  \n",
       "std                  0.288047                0.243330             10.655898  \n",
       "min                  0.000000                0.000000              0.000000  \n",
       "25%                  0.000000                0.000000              2.000000  \n",
       "50%                  0.000000                0.000000              5.000000  \n",
       "75%                  0.000000                0.000000             13.000000  \n",
       "max                  5.000000                5.000000            100.000000  \n",
       "\n",
       "[8 rows x 76 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>auxiliary_verb_frequency</th>\n",
       "      <th>modal_verb_frequency</th>\n",
       "      <th>modifier_adverb_frequency</th>\n",
       "      <th>linking_adverb_frequency</th>\n",
       "      <th>place_adverb_frequency</th>\n",
       "      <th>subordinating_conjunction_frequency</th>\n",
       "      <th>correlative_conjunction_frequency</th>\n",
       "      <th>interjection_frequency</th>\n",
       "      <th>onomatopoeia_frequency</th>\n",
       "      <th>palindrome_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  \\\n",
       "0             NaN             NaN            NaN  ...   \n",
       "1             NaN             NaN            NaN  ...   \n",
       "\n",
       "   auxiliary_verb_frequency  modal_verb_frequency  modifier_adverb_frequency  \\\n",
       "0                        10                     4                          3   \n",
       "1                        19                    14                          4   \n",
       "\n",
       "   linking_adverb_frequency  place_adverb_frequency  \\\n",
       "0                         0                       1   \n",
       "1                         0                       0   \n",
       "\n",
       "   subordinating_conjunction_frequency  correlative_conjunction_frequency  \\\n",
       "0                                    6                                 12   \n",
       "1                                    6                                  5   \n",
       "\n",
       "   interjection_frequency  onomatopoeia_frequency  palindrome_frequency  \n",
       "0                       0                       0                    12  \n",
       "1                       0                       1                    25  \n",
       "\n",
       "[2 rows x 78 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_set.to_csv('new_trainning_set.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new_ts = pd.read_csv('new_trainning_set.csv', sep=',', encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>auxiliary_verb_frequency</th>\n",
       "      <th>modal_verb_frequency</th>\n",
       "      <th>modifier_adverb_frequency</th>\n",
       "      <th>linking_adverb_frequency</th>\n",
       "      <th>place_adverb_frequency</th>\n",
       "      <th>subordinating_conjunction_frequency</th>\n",
       "      <th>correlative_conjunction_frequency</th>\n",
       "      <th>interjection_frequency</th>\n",
       "      <th>onomatopoeia_frequency</th>\n",
       "      <th>palindrome_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  \\\n",
       "0             NaN             NaN            NaN  ...   \n",
       "1             NaN             NaN            NaN  ...   \n",
       "2             NaN             NaN            NaN  ...   \n",
       "\n",
       "   auxiliary_verb_frequency  modal_verb_frequency  modifier_adverb_frequency  \\\n",
       "0                        10                     4                          3   \n",
       "1                        19                    14                          4   \n",
       "2                        12                     4                          2   \n",
       "\n",
       "   linking_adverb_frequency  place_adverb_frequency  \\\n",
       "0                         0                       1   \n",
       "1                         0                       0   \n",
       "2                         0                       0   \n",
       "\n",
       "   subordinating_conjunction_frequency  correlative_conjunction_frequency  \\\n",
       "0                                    6                                 12   \n",
       "1                                    6                                  5   \n",
       "2                                    1                                  3   \n",
       "\n",
       "   interjection_frequency  onomatopoeia_frequency  palindrome_frequency  \n",
       "0                       0                       0                    12  \n",
       "1                       0                       1                    25  \n",
       "2                       0                       0                    13  \n",
       "\n",
       "[3 rows x 78 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_new_ts.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
